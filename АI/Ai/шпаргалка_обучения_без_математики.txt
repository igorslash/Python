Шпаргалка: NLP-инженер против Математики
Математический термин	Что это на самом деле (образ)	Что писать в PyTorch / Код
Dot Product (Скалярное произведение)	Сравнение. Поиск сходства между словами. Чем выше число, тем больше слова "подходят" друг другу.	query @ key.T или torch.bmm
Softmax	Демократия. Превращает любые дикие числа в понятные проценты (от 0 до 1), которые в сумме дают 100%.	F.softmax(scores, dim=-1)
Scaling (Деление на 
)	Регулятор громкости. Чтобы числа не стали слишком огромными и не "оглушили" нейросеть (затухание градиента).	scores / np.sqrt(d_k)
Embedding	Переводчик. Заменяет букву/слово на список характеристик (вектор). Например: "Король" = [высокий, мужчина, корона].	nn.Embedding(num, dim)
Hidden State (
)	Краткосрочная память. Блокнот, куда нейронка записывает, что она поняла из прочитанного текста на данный момент.	Результат от nn.RNN или nn.GRU
Dropout	Тренировка с закрытыми глазами. Случайное выключение нейронов, чтобы модель не "зубрила" ответы, а училась думать.	nn.Dropout(p=0.5)
Perplexity	Шкала растерянности. Сколько вариантов ответа модель перебирает в уме. Чем меньше — тем она увереннее в себе.	torch.exp(loss)
Золотое правило «Тройки» для Attention:
Если забыли порядок действий в коде, вспомните С.У.В.:
Сравни (умножь)
Утихомирь (подели)
Вероятность (софтмакс